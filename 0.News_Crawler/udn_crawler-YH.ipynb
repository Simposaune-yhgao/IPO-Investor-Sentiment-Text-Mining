{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver  \n",
    "from selenium.webdriver.common.action_chains import ActionChains  \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4.element import NavigableString\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd \n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\Text Mining_YHK\\0_NewsCrawer\n"
     ]
    }
   ],
   "source": [
    "os.chdir('C:/Users/USER/Desktop/Text Mining_YHK/0_NewsCrawer')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. IPO Data**\n",
    "* Create IPO dataframe based on each season\n",
    "* IPO Data processing : \n",
    "    * create date range for news searching\n",
    "    * drop foreign company(KY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPO = pd.read_excel('IPO_RawData.xlsx')\n",
    "IPO = IPO[IPO['ipo_date'] >= '2019-01-01'].reset_index(drop=True)\n",
    "#print(IPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_dtime(df):\n",
    "    df['ipo_date'] = pd.to_datetime(df['ipo_date'])\n",
    "    df['establish_date'] = pd.to_datetime(df['establish_date'])\n",
    "\n",
    "trans_dtime(IPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(IPO.loc[0:1,'ipo_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df['stock_code'] = df['name'].str[:4]\n",
    "    df['name'] = df['name'].str[5:]\n",
    "    df['age'] = df['ipo_date'] - IPO['establish_date']\n",
    "    df['age'] = df['age']/timedelta(days=365)\n",
    "    df['ipo_year'] = df['ipo_date'].dt.year\n",
    "    df['allot'] = df['allot']*0.01 #平均中籤率\n",
    "    df['ipo_month'] = df['ipo_date'].dt.month\n",
    "\n",
    "clean(IPO)\n",
    "IPO['KY'] = 0\n",
    "IPO.loc[IPO['name'].str.contains('KY'),'KY'] = 1 #名字有KY的 KY欄輸1\n",
    "\n",
    "IPO['underprice'] = IPO['close_price']/IPO['offer_price'] - 1 ##有missing '-' \n",
    "\n",
    "IPO['oversub'] = 1/IPO['allot'] \n",
    "\n",
    "# create news search range\n",
    "#   為了包含某公司的前一個月到IPO前一天的新聞\n",
    "s = [] \n",
    "e = []\n",
    "    \n",
    "for j in IPO['ipo_date']:\n",
    "    s.append((j - relativedelta(months=1)).strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "for i in IPO['ipo_date']:\n",
    "    e.append((i- relativedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "IPO['start_date'] = s\n",
    "IPO['end_date'] = e\n",
    "\n",
    "# USE_CODE = IPO[IPO['KY'] == 0][['stock_code']].sort_values(by='stock_code', ascending = 'False').reset_index(drop = True)\n",
    "\n",
    "##處裡過的IPO df\n",
    "IPO_USE = IPO[IPO['KY'] == 0].reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipo_group(i,j):\n",
    "    return IPO_USE[(IPO_USE['ipo_year'] == i) & IPO_USE['ipo_month'].isin(j)].reset_index(drop = True)\n",
    "\n",
    "IPO_1904, IPO_1908, IPO_1912 = ipo_group(2019,list(range(1,5))), ipo_group(2019,list(range(5,9))), ipo_group(2019,list(range(9,13)))\n",
    "IPO_2004, IPO_2008, IPO_2012 = ipo_group(2020,list(range(1,5))), ipo_group(2020,list(range(5,9))), ipo_group(2020,list(range(9,13)))\n",
    "IPO_2104, IPO_2108, IPO_2112 = ipo_group(2021,list(range(1,5))), ipo_group(2021,list(range(5,9))), ipo_group(2021,list(range(9,13)))\n",
    "IPO_2204, IPO_2208, IPO_2212 = ipo_group(2022,list(range(1,5))), ipo_group(2022,list(range(5,9))), ipo_group(2022,list(range(9,13)))\n",
    "IPO_2304, IPO_2308, IPO_2312 = ipo_group(2023,list(range(1,5))), ipo_group(2023,list(range(5,9))), ipo_group(2023,list(range(9,13)))\n",
    "IPO_2404, IPO_2408, IPO_2412 = ipo_group(2024,list(range(1,5))), ipo_group(2024,list(range(5,9))), ipo_group(2011,list(range(9,13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ipo_year</th>\n",
       "      <th>ipo_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>十銓</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>大詠城</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>錸寶</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>易發</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M31</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>詠昇</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>元翎</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>勤凱</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>樂斯科</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>緯穎</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>雍智科技</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  ipo_year  ipo_month\n",
       "0     十銓      2019          1\n",
       "1    大詠城      2019          1\n",
       "2     錸寶      2019          1\n",
       "3     易發      2019          1\n",
       "4    M31      2019          1\n",
       "5     詠昇      2019          2\n",
       "6     元翎      2019          3\n",
       "7     勤凱      2019          3\n",
       "8    樂斯科      2019          3\n",
       "9     緯穎      2019          3\n",
       "10  雍智科技      2019          4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPO_1904[['name','ipo_year','ipo_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "年: [2019]  月： [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print('年:',IPO_1904['ipo_year'].unique(),' 月：',IPO_1904['ipo_month'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>易發</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>2019-01-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  start_date    end_date\n",
       "3   易發  2018-12-18  2019-01-17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPO[IPO['name'] == '易發'][['name','start_date','end_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. WebCrawler Function**\n",
    "* open news page\n",
    "* collect news title date name for each company\n",
    "* collect news content for each company\n",
    "* save as excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_udn():\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.maximize_window()\n",
    "    driver.get('https://udndata.com/ndapp/Index?cp=udn')\n",
    "    # fixed ip log in\n",
    "    #driver.find_element(\"xpath\", \"/html/body/div[@id='container']/main[@class='index']\"\\\n",
    "    #                             +\"/div[@class='wrapper clearfix']/aside[@class='service']\"\\\n",
    "    #                             +\"/div[@class='member']/div[@class='sign-in']\").click()\n",
    "    driver.find_element(\"xpath\", \"/html/body/div[@id='container']/header/\"\\\n",
    "                                    +\"div[@class='wrapper top clearfix']/\"\\\n",
    "                                    +\"ul[@class='menu clearfix']/li[2]/a[@class='fa-group']\").click()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get news_title, date, name; use in get_news() \n",
    "def get_title_date_name(x,y):\n",
    "    # title, append to title list\n",
    "    for title in x.find_all(class_ = \"control-pic\"):\n",
    "        title_list.append(title.a.string.replace(\"\\n\",\"\"))\n",
    "    # date, append to date list\n",
    "    for date in x.find_all(class_ = \"source\"):\n",
    "        date_list.append(date.string[:10])\n",
    "    # name, append to name list\n",
    "    for i in range(len(x.find_all(class_ = \"control-pic\"))):\n",
    "        name_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get news content; use in get_news()\n",
    "def get_content(j):\n",
    "    #open new news tab \n",
    "    new_tab = driver.find_element(\"xpath\", \"/html/body/div/main/div/div[1]/section/div[6]/ul/li[\"+str(j)+\"]/div/h2/a\") \n",
    "    action = ActionChains(driver)\n",
    "    action.move_to_element(new_tab).key_down(Keys.CONTROL).click(new_tab).key_up(Keys.CONTROL).perform() # new tab\n",
    "    time.sleep(3) # wait for new tab \n",
    "    driver.switch_to.window(driver.window_handles[1]) # switch to new tab\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # check log in status\n",
    "    log_in = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "    if log_in.find(string = \"會員登入\") == \"會員登入\":\n",
    "        # login again\n",
    "        driver.find_element(\"xpath\",\"/html/body/div/main/div/div[1]/section/div[3]/a[1]\").click()\n",
    "    elif log_in.find(string = \"錯誤訊息\") == \"錯誤訊息\":\n",
    "        # refresh window\n",
    "        driver.refresh()\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        pass\n",
    "    # get content of new tab, append to content list\n",
    "    bsobj = BeautifulSoup(driver.page_source,\"lxml\") \n",
    "    content = bsobj.find(\"article\")\n",
    "    content_list.append(content.get_text().replace(\"\\n\",\"\")\\\n",
    "                        .replace(\"\\t\",\"\").replace(\"\\u3000\",\"\").replace(\" \",\"\"))\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # close new tab\n",
    "    driver.close()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # switch back to search result page\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(name,start_date,end_date):\n",
    "    # change url\n",
    "    url = driver.current_url\n",
    "    driver.get(url)\n",
    "\n",
    "    # input search element\n",
    "    search_elem = driver.find_element(\"xpath\",'/html/body/div[1]/main/div/div[1]/section[1]/div[2]/form/div[1]/div[1]/input')\n",
    "    search_elem.send_keys(name) # input company name\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # input search date range\n",
    "    start = driver.find_element(\"id\",'datepicker-start')\n",
    "    start.send_keys(u\"\"+start_date)\n",
    "    time.sleep(1)\n",
    "    end = driver.find_element(\"id\",'datepicker-end')\n",
    "    end.send_keys(u\"\"+end_date)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # click on search button\n",
    "    driver.find_element(\"xpath\",\"/html/body/div[1]/main/div/div[1]/section[1]/div[2]/form/button\").click()\n",
    "\n",
    "    # click on show 50 results in one page button\n",
    "    select = Select(driver.find_element(\"id\",'sharepage'))\n",
    "    select.select_by_value(\"50\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Find news result number\n",
    "    news = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "    time.sleep(1)\n",
    "    news_num = int(news.find_all(class_= \"mark\")[1].text)\n",
    "\n",
    "    # Find news page\n",
    "    if (news_num/50).is_integer():\n",
    "        news_page = int(news_num/50) \n",
    "    else:\n",
    "        news_page = int(news_num/50)+1\n",
    "\n",
    "    ## For loop to change page and get news content\n",
    "    for i in range(0,news_page+1):\n",
    "        # no page\n",
    "        if i == 0:\n",
    "            pass\n",
    "        # page 1\n",
    "        elif i == 1:\n",
    "            get_title_date_name(news,name)\n",
    "            for j in range(1,(news_num-(i*50-51))):\n",
    "                if j <= 50:\n",
    "                    get_content(j)\n",
    "        # other page\n",
    "        else:\n",
    "            #click to change page\n",
    "            driver.find_element(\"xpath\",\"/html/body/div[@id='container']/main/div[@class='wrapper clearfix']/div[@id='mainbar']\"\\\n",
    "                                         +\"/section[@class='list-news']/div[@class='page-number page-number-web']/a[\"+str(i+2)+\"]\").click()\n",
    "            driver.get(driver.current_url)\n",
    "            news = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "            get_title_date_name(news,name)\n",
    "            time.sleep(1)\n",
    "            for j in range(1,(news_num-(i*50-51))):\n",
    "                if j <= 50:\n",
    "                    get_content(j)\n",
    "    \n",
    "    ### return to search page\n",
    "    driver.find_element(\"xpath\",\"/html/body/div/header/div[2]/div/div[1]/div/a[2]\").click()\n",
    "    gc.collect()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel(title):\n",
    "    df = pd.DataFrame({'name':name_list,'date':date_list,'title':title_list,'content':content_list})\n",
    "    df.to_excel('./IPO_Data/'+title+'.xlsx', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **3. examination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change url\n",
    "url = driver.current_url\n",
    "driver.get(url)\n",
    "\n",
    "# input search element\n",
    "search_elem = driver.find_element(\"xpath\",'/html/body/div[1]/main/div/div[1]/section[1]/div[2]/form/div[1]/div[1]/input')\n",
    "search_elem.send_keys(\"碩天\") # input company name\n",
    "time.sleep(1)\n",
    "    \n",
    "# input search date range\n",
    "start = driver.find_element(\"id\",'datepicker-start')\n",
    "start.send_keys(u\"2009-11-23\")\n",
    "time.sleep(1)\n",
    "end = driver.find_element(\"id\",'datepicker-end')\n",
    "end.send_keys(u\"2009-12-22\")\n",
    "time.sleep(1)\n",
    "    \n",
    "# click on search button\n",
    "driver.find_element(\"xpath\",\"/html/body/div[1]/main/div/div[1]/section[1]/div[2]/form/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on show 50 results in one page button\n",
    "select = Select(driver.find_element(\"id\",'sharepage'))\n",
    "select.select_by_value(\"50\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Find news result number\n",
    "news = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "time.sleep(1)\n",
    "news_num = int(news.find_all(class_= \"mark\")[1].text)\n",
    "\n",
    "# Find news page\n",
    "if (news_num/50).is_integer():\n",
    "    news_page = int(news_num/50) \n",
    "else:\n",
    "    news_page = int(news_num/50)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "date_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in news.find_all(class_ = \"control-pic\"):\n",
    "    title_list.append(title.a.string.replace(\"\\n\",\"\"))\n",
    "# date, append to date list\n",
    "for date in news.find_all(class_ = \"source\"):\n",
    "    date_list.append(date.string[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.碩天科技23日 掛牌上市', '2.五公司 趕搭資金行情及時車', '3.看ECFA發酵程度', '4.蜜月新人 今年台股包大禮', '5.新股領軍 元月行情可期']\n",
      "['2009-12-21', '2009-12-21', '2009-12-20', '2009-12-19', '2009-12-19']\n"
     ]
    }
   ],
   "source": [
    "print(title_list[:5])\n",
    "print(date_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tab = driver.find_element(\"xpath\", \"/html/body/div/main/div/div[1]/section/div[6]/ul/li[\"+str(1)+\"]/div/h2/a\") \n",
    "action = ActionChains(driver)\n",
    "action.move_to_element(new_tab).key_down(Keys.CONTROL).click(new_tab).key_up(Keys.CONTROL).perform() # new tab\n",
    "time.sleep(3) # wait for new tab \n",
    "driver.switch_to.window(driver.window_handles[1]) # switch to new tab\n",
    "time.sleep(1)\n",
    "\n",
    "bsobj = BeautifulSoup(driver.page_source,\"lxml\") \n",
    "content_list = []\n",
    "content = bsobj.find(\"article\")\n",
    "#print(type(content))\n",
    "\n",
    "content_list.append(content.get_text().replace(\"\\n\",\"\")\\\n",
    "                        .replace(\"\\t\",\"\").replace(\"\\u3000\",\"\").replace(\" \",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['以製造不斷電電源系統(UPS)揚名海外的碩天科技公司在日前已舉辦上市前法說會，並預計於23日正式掛牌。碩天科技於1997年成立，產品包括不斷電電源系統(UPS)、可攜式電源、電源保護及電源管理等，並藉由自有品牌(CyberPower)銷售至歐美地區。客戶包括美國主要零售商BestBuy、CircuitCity和Wal-Mart及經銷商IngramMicro、TechData和D&H等。碩天科技目前專注於生產小功率(5KVA以下)的UPS產品，並主打美國市場，目前已成為美國零售通路前兩大品牌廠商。碩天總經理何溓洵表示，因應公司發展，碩天科技今年開始增加中功率(5KVA~10KVA)產品線與新通路據點，包括日本、奈及利亞等地區，將持續開發經銷商通路市場，預期未來幾年將持續帶動公司成長。(項孟汝)']\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "#print(bsobj.prettify())\n",
    "print(content_list[:5])\n",
    "print(type(content))\n",
    "#/html/body/div/main/div/div[1]/section/div[6]/ul/li[\"+str(j)+\"]/div/h2/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in news.find_all(class_ = \"control-pic\"):\n",
    "    print(title.a.string.replace(\"\\n\",\"\"))\n",
    "    link = \"https://udndata.com\" + title.a[\"href\"]\n",
    "#     print(link)\n",
    "    resp = requests.get(link)\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "#     content = soup.find(\"article\")\n",
    "    #print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([x for x in name_list if x =='易發'])\n",
    "print(IPO_1904['name'])\n",
    "#print(date_list[:5])\n",
    "#print(content_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Run by every four months**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2019/01~04\n",
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1904[~IPO_1904['name'].isin(['易發'])]['name'], IPO_1904[~IPO_1904['name'].isin(['易發'])]['start_date'], IPO_1904[~IPO_1904['name'].isin(['易發'])]['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "df_1904 = excel('1904')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2019/05~08\n",
    "for i,j,k in zip(IPO_1908['name'],IPO_1908['start_date'], IPO_1908['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1908 = excel('1908')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2019/09~12\n",
    "for i,j,k in zip(IPO_1912['name'],IPO_1912['start_date'], IPO_1912['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1912 = excel('1912')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2020/01~04\n",
    "for i,j,k in zip(IPO_2004['name'],IPO_2004['start_date'], IPO_2004['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_2004 = excel('2004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2020/05~08\n",
    "for i,j,k in zip(IPO_2008['name'],IPO_2008['start_date'], IPO_2008['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_2008 = excel('2008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2020/09~12\n",
    "for i,j,k in zip(IPO_2012['name'],IPO_2012['start_date'], IPO_2012['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_2012 = excel('2012')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2021/01~04\n",
    "for i,j,k in zip(IPO_2104['name'],IPO_2104['start_date'], IPO_2104['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_2104 = excel('2104')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2121/05~08\n",
    "for i,j,k in zip(IPO_2108['name'],IPO_2108['start_date'], IPO_2108['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_2108 = excel('2108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2121/09~12\n",
    "for i,j,k in zip(IPO_2112['name'],IPO_2112['start_date'], IPO_2112['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_2112 = excel('2112')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
