{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver  \n",
    "from selenium.webdriver.common.action_chains import ActionChains  \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4.element import NavigableString\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import pandas as pd \n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3899"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. IPO Data**\n",
    "* Create IPO dataframe based on each season\n",
    "* IPO Data processing : \n",
    "    * create date range for news searching\n",
    "    * drop foreign company(KY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  tse_ind tse_ind_name underwrite_date underwrite_announcement  \\\n",
      "0       1815 富喬       28  M2328 電子零組件      2006-01-17              2006-01-05   \n",
      "1      3130 一零四       30  M2330 資訊服務業      2006-02-13              2006-01-12   \n",
      "2      3221 台嘉碩       27  M2327 通信網路業      2006-02-16              2006-02-09   \n",
      "3      3388 崇越電       28  M2328 電子零組件      2006-02-16              2006-02-09   \n",
      "4       3390 旭軟       28  M2328 電子零組件      2006-02-15              2006-02-08   \n",
      "..          ...      ...          ...             ...                     ...   \n",
      "657     2752 豆府       16   M2700 觀光事業      2019-09-17              2019-09-12   \n",
      "658     6491 晶碩       22   M1722 生技醫療      2019-09-27              2019-09-25   \n",
      "659   6690 安碁資訊       30  M2330 資訊服務業      2019-10-23              2019-10-18   \n",
      "660   6698 旭暉應材       31  M2331 其他電子業      2019-11-18              2019-11-13   \n",
      "661  4439 冠星-KY        4   M1400 紡織纖維      2019-11-27              2019-11-25   \n",
      "\n",
      "      ipo_date otc_ipo_date tse_ipo_date establish_date ipo_market  ...  \\\n",
      "0   2006-01-23   2006-01-23          NaT     1999-01-14        OTC  ...   \n",
      "1   2006-02-17          NaT   2006-02-17     1993-10-30        TSE  ...   \n",
      "2   2006-02-22   2006-02-22          NaT     1997-11-10        OTC  ...   \n",
      "3   2006-02-22   2006-02-22          NaT     1994-02-21        OTC  ...   \n",
      "4   2006-02-22   2006-02-22          NaT     1998-10-12        OTC  ...   \n",
      "..         ...          ...          ...            ...        ...  ...   \n",
      "657 2019-09-25   2019-09-25          NaT     2008-01-23        OTC  ...   \n",
      "658 2019-10-07          NaT   2019-10-07     2009-08-26        TSE  ...   \n",
      "659 2019-10-30   2019-10-30          NaT     2000-05-29        OTC  ...   \n",
      "660 2019-11-25          NaT   2019-11-25     2007-05-25        TSE  ...   \n",
      "661 2019-12-05          NaT   2019-12-05     2013-05-21        TSE  ...   \n",
      "\n",
      "    trading_volume(k)_2 close_price_3 trading_volume(k)_3 close_price_4  \\\n",
      "0                1348.0          28.2              4177.0          28.2   \n",
      "1                 453.0         170.0               626.0         173.5   \n",
      "2                 749.0          45.8               371.0          48.4   \n",
      "3                 621.0         133.0               550.0         145.0   \n",
      "4                 293.0          40.1               536.0          40.2   \n",
      "..                  ...           ...                 ...           ...   \n",
      "657               245.0         110.0               124.0         110.0   \n",
      "658               834.0         168.5               340.0         162.5   \n",
      "659               501.0         124.0               749.0         121.0   \n",
      "660               705.0          73.1               335.0          71.3   \n",
      "661                 NaN           NaN                 NaN           NaN   \n",
      "\n",
      "    trading_volume(k)_4  close_price_5  trading_volume(k)_5  \\\n",
      "0                1296.0          28.15                903.0   \n",
      "1                 469.0         185.50                722.0   \n",
      "2                 442.0          51.70               1609.0   \n",
      "3                 888.0         138.00                629.0   \n",
      "4                 403.0          39.60                250.0   \n",
      "..                  ...            ...                  ...   \n",
      "657               108.0         115.50                219.0   \n",
      "658               636.0         164.00                424.0   \n",
      "659               364.0         118.00                294.0   \n",
      "660               404.0          69.70                497.0   \n",
      "661                 NaN            NaN                  NaN   \n",
      "\n",
      "     esm_last_close_price  esm_draw_close_price         audit  \n",
      "0                   32.10                   NaN  勤業眾信聯合會計師事務所  \n",
      "1                  187.00                   NaN  安侯建業聯合會計師事務所  \n",
      "2                   50.00                   NaN  勤業眾信聯合會計師事務所  \n",
      "3                  175.00                   NaN  安侯建業聯合會計師事務所  \n",
      "4                   44.50                 45.00    致遠聯合會計師事務所  \n",
      "..                    ...                   ...           ...  \n",
      "657                134.72                128.00  勤業眾信聯合會計師事務所  \n",
      "658                190.00                191.00    安永聯合會計師事務所  \n",
      "659                150.00                170.99  安侯建業聯合會計師事務所  \n",
      "660                 79.11                 79.70    資誠聯合會計師事務所  \n",
      "661                   NaN                   NaN    資誠聯合會計師事務所  \n",
      "\n",
      "[662 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "IPO = pd.read_excel('IPO_RawData.xlsx')\n",
    "IPO = IPO[IPO['ipo_date'] >= '2006-01-01'].reset_index(drop=True)\n",
    "print(IPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df['stock_code'] = df['name'].str[:4]\n",
    "    df['name'] = df['name'].str[5:]\n",
    "    df['age'] = df['ipo_date'] - IPO['establish_date']\n",
    "    df['age'] = df['age']/timedelta(days=365)\n",
    "    df['ipo_year'] = df['ipo_date'].dt.year\n",
    "    df['allot'] = df['allot']*0.01\n",
    "    df['ipo_month'] = df['ipo_date'].dt.month\n",
    "\n",
    "clean(IPO)\n",
    "IPO['KY'] = 0\n",
    "IPO.loc[IPO['name'].str.contains('KY'),'KY'] = 1 #名字有KY的 KY欄輸1\n",
    "\n",
    "IPO['underprice'] = IPO['close_price']/IPO['offer_price'] - 1\n",
    "\n",
    "IPO['oversub'] = 1/IPO['allot'] \n",
    "\n",
    "# create news search range\n",
    "#   為了包含某公司的一個月到IPO前一天的新聞\n",
    "s = [] \n",
    "e = []\n",
    "    \n",
    "for j in IPO['ipo_date']:\n",
    "    s.append((j - relativedelta(months=1)).strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "for i in IPO['ipo_date']:\n",
    "    e.append((i- relativedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "IPO['start_date'] = s\n",
    "IPO['end_date'] = e\n",
    "\n",
    "# USE_CODE = IPO[IPO['KY'] == 0][['stock_code']].sort_values(by='stock_code', ascending = 'False').reset_index(drop = True)\n",
    "IPO_USE = IPO[IPO['KY'] == 0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipo_group(i,j):\n",
    "    return IPO_USE[(IPO_USE['ipo_year'] == i) & IPO_USE['ipo_month'].isin(j)].reset_index(drop = True)\n",
    "\n",
    "IPO_0604, IPO_0608, IPO_0612 = ipo_group(2006,list(range(1,5))), ipo_group(2006,list(range(5,9))), ipo_group(2006,list(range(9,13)))\n",
    "IPO_0704, IPO_0708, IPO_0712 = ipo_group(2007,list(range(1,5))), ipo_group(2007,list(range(5,9))), ipo_group(2007,list(range(9,13)))\n",
    "IPO_0804, IPO_0808, IPO_0812 = ipo_group(2008,list(range(1,5))), ipo_group(2008,list(range(5,9))), ipo_group(2008,list(range(9,13)))\n",
    "IPO_0904, IPO_0908, IPO_0912 = ipo_group(2009,list(range(1,5))), ipo_group(2009,list(range(5,9))), ipo_group(2009,list(range(9,13)))\n",
    "IPO_1004, IPO_1008, IPO_1012 = ipo_group(2010,list(range(1,5))), ipo_group(2010,list(range(5,9))), ipo_group(2010,list(range(9,13)))\n",
    "IPO_1104, IPO_1108, IPO_1112 = ipo_group(2011,list(range(1,5))), ipo_group(2011,list(range(5,9))), ipo_group(2011,list(range(9,13)))\n",
    "IPO_1204, IPO_1208, IPO_1212 = ipo_group(2012,list(range(1,5))), ipo_group(2012,list(range(5,9))), ipo_group(2012,list(range(9,13)))\n",
    "IPO_1304, IPO_1308, IPO_1312 = ipo_group(2013,list(range(1,5))), ipo_group(2013,list(range(5,9))), ipo_group(2013,list(range(9,13)))\n",
    "IPO_1404, IPO_1408, IPO_1412 = ipo_group(2014,list(range(1,5))), ipo_group(2014,list(range(5,9))), ipo_group(2014,list(range(9,13)))\n",
    "IPO_1504, IPO_1508, IPO_1512 = ipo_group(2015,list(range(1,5))), ipo_group(2015,list(range(5,9))), ipo_group(2015,list(range(9,13)))\n",
    "IPO_1604, IPO_1608, IPO_1612 = ipo_group(2016,list(range(1,5))), ipo_group(2016,list(range(5,9))), ipo_group(2016,list(range(9,13)))\n",
    "IPO_1704, IPO_1708, IPO_1712 = ipo_group(2017,list(range(1,5))), ipo_group(2017,list(range(5,9))), ipo_group(2017,list(range(9,13)))\n",
    "IPO_1804, IPO_1808, IPO_1812 = ipo_group(2018,list(range(1,5))), ipo_group(2018,list(range(5,9))), ipo_group(2018,list(range(9,13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ipo_year</th>\n",
       "      <th>ipo_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>富喬</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一零四</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>台嘉碩</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>崇越電</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>旭軟</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>益通</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>恒耀</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>南電</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>聯鈞</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>朋程</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  ipo_year  ipo_month\n",
       "0   富喬      2006          1\n",
       "1  一零四      2006          2\n",
       "2  台嘉碩      2006          2\n",
       "3  崇越電      2006          2\n",
       "4   旭軟      2006          2\n",
       "5   益通      2006          3\n",
       "6   恒耀      2006          3\n",
       "7   南電      2006          4\n",
       "8   聯鈞      2006          4\n",
       "9   朋程      2006          4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPO_0604[['name','ipo_year','ipo_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "年: [2006]  月： [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print('年:',IPO_0604['ipo_year'].unique(),' 月：',IPO_0604['ipo_month'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>益通</td>\n",
       "      <td>2006-02-08</td>\n",
       "      <td>2006-03-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  start_date    end_date\n",
       "5   益通  2006-02-08  2006-03-07"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPO[IPO['name'] == '益通'][['name','start_date','end_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. WebCrawler Function**\n",
    "* open news page\n",
    "* collect news title date name for each company\n",
    "* collect news content for each company\n",
    "* save as excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_udn():\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.maximize_window()\n",
    "    driver.get('https://udndata.com/ndapp/Index?cp=udn')\n",
    "    # fixed ip log in\n",
    "    #driver.find_element(\"xpath\", \"/html/body/div[@id='container']/main[@class='index']\"\\\n",
    "    #                             +\"/div[@class='wrapper clearfix']/aside[@class='service']\"\\\n",
    "    #                             +\"/div[@class='member']/div[@class='sign-in']\").click()\n",
    "    driver.find_element(\"xpath\", \"/html/body/div[@id='container']/header/\"\\\n",
    "                                    +\"div[@class='wrapper top clearfix']/\"\\\n",
    "                                    +\"ul[@class='menu clearfix']/li[2]/a[@class='fa-group']\").click()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get news_title, date, name; use in get_news() \n",
    "def get_title_date_name(x,y):\n",
    "    # title, append to title list\n",
    "    for title in x.find_all(class_ = \"control-pic\"):\n",
    "        title_list.append(title.a.string.replace(\"\\n\",\"\"))\n",
    "    # date, append to date list\n",
    "    for date in x.find_all(class_ = \"source\"):\n",
    "        date_list.append(date.string[:10])\n",
    "    # name, append to name list\n",
    "    for i in range(len(x.find_all(class_ = \"control-pic\"))):\n",
    "        name_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get news content; use in get_news()\n",
    "def get_content(j):\n",
    "    #open new news tab \n",
    "    new_tab = driver.find_element(\"xpath\", \"/html/body/div/main/div/div[1]/section/div[6]/ul/li[\"+str(j)+\"]/div/h2/a\") \n",
    "    action = ActionChains(driver)\n",
    "    action.move_to_element(new_tab).key_down(Keys.CONTROL).click(new_tab).key_up(Keys.CONTROL).perform() # new tab\n",
    "    time.sleep(3) # wait for new tab \n",
    "    driver.switch_to.window(driver.window_handles[1]) # switch to new tab\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # check log in status\n",
    "    log_in = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "    if log_in.find(string = \"會員登入\") == \"會員登入\":\n",
    "        # login again\n",
    "        driver.find_element(\"xpath\",\"/html/body/div/main/div/div[1]/section/div[3]/a[1]\").click()\n",
    "    elif log_in.find(string = \"錯誤訊息\") == \"錯誤訊息\":\n",
    "        # refresh window\n",
    "        driver.refresh()\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        pass\n",
    "    # get content of new tab, append to content list\n",
    "    bsobj = BeautifulSoup(driver.page_source,\"lxml\") \n",
    "    content = bsobj.find(\"article\")\n",
    "    content_list.append(content.get_text().replace(\"\\n\",\"\")\\\n",
    "                        .replace(\"\\t\",\"\").replace(\"\\u3000\",\"\").replace(\" \",\"\"))\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # close new tab\n",
    "    driver.close()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # switch back to search result page\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(name,start_date,end_date):\n",
    "    # change url\n",
    "    url = driver.current_url\n",
    "    driver.get(url)\n",
    "\n",
    "    # input search element\n",
    "    search_elem = driver.find_element(\"xpath\",'/html/body/div[1]/main/div/div[1]/section[1]/div[2]/form/div[1]/div[1]/input')\n",
    "    search_elem.send_keys(name) # input company name\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # input search date range\n",
    "    start = driver.find_element(\"id\",'datepicker-start')\n",
    "    start.send_keys(u\"\"+start_date)\n",
    "    time.sleep(1)\n",
    "    end = driver.find_element(\"id\",'datepicker-end')\n",
    "    end.send_keys(u\"\"+end_date)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # click on search button\n",
    "    driver.find_element(\"xpath\",\"/html/body/div[1]/main/div/div[1]/section[1]/div[2]/form/button\").click()\n",
    "\n",
    "    # click on show 50 results in one page button\n",
    "    select = Select(driver.find_element(\"id\",'sharepage'))\n",
    "    select.select_by_value(\"50\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Find news result number\n",
    "    news = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "    time.sleep(1)\n",
    "    news_num = int(news.find_all(class_= \"mark\")[1].text)\n",
    "\n",
    "    # Find news page\n",
    "    if (news_num/50).is_integer():\n",
    "        news_page = int(news_num/50) \n",
    "    else:\n",
    "        news_page = int(news_num/50)+1\n",
    "\n",
    "    ## For loop to change page and get news content\n",
    "    for i in range(0,news_page+1):\n",
    "        # no page\n",
    "        if i == 0:\n",
    "            pass\n",
    "        # page 1\n",
    "        elif i == 1:\n",
    "            get_title_date_name(news,name)\n",
    "            for j in range(1,(news_num-(i*50-51))):\n",
    "                if j <= 50:\n",
    "                    get_content(j)\n",
    "        # other page\n",
    "        else:\n",
    "            #click to change page\n",
    "            driver.find_element(\"xpath\",\"/html/body/div[@id='container']/main/div[@class='wrapper clearfix']/div[@id='mainbar']\"\\\n",
    "                                         +\"/section[@class='list-news']/div[@class='page-number page-number-web']/a[\"+str(i+2)+\"]\").click()\n",
    "            driver.get(driver.current_url)\n",
    "            news = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "            get_title_date_name(news,name)\n",
    "            time.sleep(1)\n",
    "            for j in range(1,(news_num-(i*50-51))):\n",
    "                if j <= 50:\n",
    "                    get_content(j)\n",
    "    \n",
    "    ### return to search page\n",
    "    driver.find_element(\"xpath\",\"/html/body/div/header/div[2]/div/div[1]/div/a[2]\").click()\n",
    "    gc.collect()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel(title):\n",
    "    df = pd.DataFrame({'name':name_list,'date':date_list,'title':title_list,'content':content_list})\n",
    "    df.to_excel('C:/Users/USER/Desktop/Text Mining/IPO_Data/'+title+'.xlsx', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome('/chromedriver')  \n",
    "#open_udn()\n",
    "\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe') #這行和下行要改(每年)\n",
    "driver = webdriver.Chrome(service = cService)##這行和上行要改(每年)\n",
    "open_udn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change url\n",
    "url = driver.current_url\n",
    "driver.get(url)\n",
    "\n",
    "# input search element\n",
    "search_elem =driver.find_element(\"xpath\", \"/html/body/div[@id='container']/main[@class='index']/div[@class='wrapper clearfix']/\"\\\n",
    "                                            +\"div[@id='mainbar']/section[@class='newsearch']/div[@class='searchBox clearfix']/\"\\\n",
    "                                            +\"form[@id='udnform']/div[@class='search']/div[@class='search-input']/input[@id='SearchString']\")\n",
    "   #search_elem = driver.find_element_by_xpath('/html/body/div[1]/main/div/div[1]/section[1]/div[2]/form/div[1]/div[1]/input')\n",
    "search_elem.send_keys(\"碩天\") # input company name\n",
    "time.sleep(1)\n",
    "    \n",
    "# input search date range\n",
    "start = driver.find_element(\"id\", \"datepicker-start\")\n",
    "#start = driver.find_element_by_id('datepicker-start')\n",
    "start.send_keys(u\"2009-11-23\")\n",
    "time.sleep(1)\n",
    "end = driver.find_element(\"id\",'datepicker-end')\n",
    "end.send_keys(u\"2009-12-22\")\n",
    "time.sleep(1)\n",
    "    \n",
    "# click on search button\n",
    "search_elem =driver.find_element(\"xpath\",\"/html/body/div[@id='container']/main[@class='index']/\"\\\n",
    "                                    +\"div[@class='wrapper clearfix']/div[@id='mainbar']/section[@class='newsearch']/\"\\\n",
    "                                    +\"div[@class='searchBox clearfix']/form[@id='udnform']/button[@class='btn']\").click()\n",
    "   #driver.find_element_by_xpath(\"/html/body/div[1]/main/div/div[1]/section[1]/div[2]/form/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on show 50 results in one page button\n",
    "select = Select(driver.find_element(\"id\", 'sharepage'))\n",
    "select.select_by_value(\"50\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Find news result number\n",
    "news = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "time.sleep(1)\n",
    "news_num = int(news.find_all(class_= \"mark\")[1].text)\n",
    "\n",
    "# Find news page\n",
    "if (news_num/50).is_integer():\n",
    "    news_page = int(news_num/50) \n",
    "else:\n",
    "    news_page = int(news_num/50)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "date_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in news.find_all(class_ = \"control-pic\"):\n",
    "    title_list.append(title.a.string.replace(\"\\n\",\"\"))\n",
    "# date, append to date list\n",
    "for date in news.find_all(class_ = \"source\"):\n",
    "    date_list.append(date.string[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "content = bsobj.find(\"article\")\n",
    "print(content)\n",
    "#content_list.append(content.get_text().replace(\"\\n\",\"\")\\\n",
    "                       # .replace(\"\\t\",\"\").replace(\"\\u3000\",\"\").replace(\" \",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for title in news.find_all(class_ = \"control-pic\"):\n",
    "    print(title.a.string.replace(\"\\n\",\"\"))\n",
    "    link = \"https://udndata.com\" + title.a[\"href\"]\n",
    "#     print(link)\n",
    "    resp = requests.get(link)\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "#     content = soup.find(\"article\")\n",
    "    print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2006-01-22\n",
      "1    2006-02-16\n",
      "2    2006-02-21\n",
      "3    2006-02-21\n",
      "Name: end_date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(IPO_0604.loc[0:3,'end_date']) #testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13676\\1602727186.py:13: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  if log_in.find(text = \"會員登入\") == \"會員登入\":\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13676\\1602727186.py:16: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  elif log_in.find(text = \"錯誤訊息\") == \"錯誤訊息\":\n"
     ]
    }
   ],
   "source": [
    "## 2006/01~04\n",
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0604['name'], IPO_0604['start_date'], IPO_0604['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "#get_news('富喬','2005-12-23','2006-01-07') #testing\n",
    "\n",
    "# driver.quit()\n",
    "df_0604 = excel('0604')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2006/05~08\n",
    "for i,j,k in zip(IPO_0608['name'],IPO_0608['start_date'], IPO_0608['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0608 = excel('0608')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "# get news of IPOs in 2006/09~12\n",
    "for i,j,k in zip(IPO_0612['name'],IPO_0612['start_date'], IPO_0612['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0612 = excel('0612')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0704['name'],IPO_0704['start_date'], IPO_0704['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0704 = excel('0704')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0708['name'],IPO_0708['start_date'], IPO_0708['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0708 = excel('0708')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0712['name'],IPO_0712['start_date'], IPO_0712['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0712 = excel('0712')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0804['name'],IPO_0804['start_date'], IPO_0804['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0804 = excel('0804')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0808['name'],IPO_0808['start_date'], IPO_0808['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0808 = excel('0808')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0812['name'],IPO_0812['start_date'], IPO_0812['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0812 = excel('0812')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0904['name'],IPO_0904['start_date'], IPO_0904['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0904 = excel('0904')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0908['name'],IPO_0908['start_date'], IPO_0908['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0908 = excel('0908')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_0912['name'],IPO_0912['start_date'], IPO_0912['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_0912 = excel('0912')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1004['name'],IPO_1004['start_date'], IPO_1004['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1004 = excel('1004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1008['name'],IPO_1008['start_date'], IPO_1008['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1008 = excel('1008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1012['name'],IPO_1012['start_date'], IPO_1012['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1012 = excel('1012')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1104['name'],IPO_1104['start_date'], IPO_1104['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1104 = excel('1104')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1108['name'],IPO_1108['start_date'], IPO_1108['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1108 = excel('1108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1112[~IPO_1112['name'].isin(['安心','傳奇'])]['name'],IPO_1112[~IPO_1112['name'].isin(['安心','傳奇'])]['start_date'], IPO_1112[~IPO_1112['name'].isin(['安心','傳奇'])]['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1112 = excel('1112')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1204['name'],IPO_1204['start_date'], IPO_1204['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1204 = excel('1204')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "driver = webdriver.Chrome('./chromedriver')  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1208['name'],IPO_1208['start_date'], IPO_1208['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1208 = excel('1208')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1212['name'],IPO_1212['start_date'], IPO_1212['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1212 = excel('1212')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1304['name'],IPO_1304['start_date'], IPO_1304['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1304 = excel('1304')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1308['name'],IPO_1308['start_date'], IPO_1308['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1308 = excel('1308')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1312[~IPO_1312['name'].isin(['大量','大江','神準'])]['name'],IPO_1312[~IPO_1312['name'].isin(['大量','大江','神準'])]['start_date'], IPO_1312[~IPO_1312['name'].isin(['大量','大江','神準'])]['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1404[~IPO_1404['name'].isin(['數字'])]['name'],IPO_1404[~IPO_1404['name'].isin(['數字'])]['start_date'], IPO_1404[~IPO_1404['name'].isin(['數字'])]['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1404 = excel('1404')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1408['name'],IPO_1408['start_date'], IPO_1408['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1408 = excel('1408')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1412['name'],IPO_1412['start_date'], IPO_1412['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1412 = excel('1412')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService) \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1504['name'],IPO_1504['start_date'], IPO_1504['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1504 = excel('1504')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1508['name'],IPO_1508['start_date'], IPO_1508['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1508 = excel('1508')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1512['name'],IPO_1512['start_date'], IPO_1512['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1512 = excel('1512')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1604['name'],IPO_1604['start_date'], IPO_1604['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1604 = excel('1604')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1608['name'],IPO_1608['start_date'], IPO_1608['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1608 = excel('1608')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPO_1612_drop = IPO_1612[~IPO_1612['name'].isin(['互動','創業家'])].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1612_drop['name'],IPO_1612_drop['start_date'], IPO_1612_drop['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1612 = excel('1612')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1704['name'],IPO_1704['start_date'], IPO_1704['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1704 = excel('1704')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1708['name'],IPO_1708['start_date'], IPO_1708['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1708 = excel('1708')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1712['name'],IPO_1712['start_date'], IPO_1712['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1712 = excel('1712')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1804['name'],IPO_1804['start_date'], IPO_1804['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1804 = excel('1804')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1808['name'],IPO_1808['start_date'], IPO_1808['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1808 = excel('1808')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive chrome\n",
    "cService = webdriver.ChromeService(executable_path='C:/Users/USER/Desktop/Text Mining/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = cService)  \n",
    "open_udn()\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "content_list = []\n",
    "\n",
    "for i,j,k in zip(IPO_1812['name'],IPO_1812['start_date'], IPO_1812['end_date']):\n",
    "    get_news(i,j,k)\n",
    "\n",
    "driver.quit()\n",
    "df_1812 = excel('1812')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
