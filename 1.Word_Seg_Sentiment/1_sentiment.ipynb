{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **新聞詞性標註，情緒計算**\n",
    "- stopword.txt\n",
    "- postive_word_YSL.xlsx\n",
    "- negative_word_YSL.xlsx\n",
    "- IPO_USECODE.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀入新聞 (斷句ed 標示ed 取權重ed)\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob( \"n_*.xlsx\")\n",
    "df = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df.append(pd.read_excel(filename))\n",
    "\n",
    "news = pd.concat(df, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀入停用詞檔\n",
    "stopwords=[]\n",
    "with open('./stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    for word in file.readlines():\n",
    "        word = word.strip()\n",
    "        stopwords.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hsieh 謝委霖字典**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_dict = pd.read_excel('postive_word_YSL.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ys = postive_dict.values.ravel().tolist()\n",
    "pos_ys.remove(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dict = pd.read_excel('negative_word_YSL.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_ys = negative_dict.values.ravel().tolist()\n",
    "neg_ys.remove(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 修正辭典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除不合理字\n",
    "neg_ys.remove('領域')\n",
    "neg_ys.remove('目標')\n",
    "neg_ys.remove('開發')\n",
    "\n",
    "# 新增字詞\n",
    "neg_ys.append('持平')\n",
    "neg_ys.append('惡化')\n",
    "neg_ys.append('赤字')\n",
    "neg_ys.append('告吹')\n",
    "neg_ys.append('波及')\n",
    "neg_ys.append('悽慘')\n",
    "neg_ys.append('悲觀')\n",
    "\n",
    "pos_ys.append('調升')\n",
    "pos_ys.append('助於')\n",
    "pos_ys.append('湧進')\n",
    "pos_ys.append('出色')\n",
    "pos_ys.append('研發')\n",
    "pos_ys.append('獲利')\n",
    "pos_ys.append('帶動')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **計算新聞中正負向字詞**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 清理文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(x,list_name):\n",
    "    a = x.replace('[','').replace(']',\"\").replace(\"'\",\"\").replace(\" \",\"\").split(',')\n",
    "    list_name.append(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "news['word_seg'].apply(lambda x: word_list(x,list_))\n",
    "news['word_clean'] = list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = ['?', '？', '!', '！', '。', ',',  '，', ';', ':', '、', '：', '；', '】', '【', '（', '）', '(', ')', '[', ']', '●', '／', '「', '」']\n",
    "news['word_clean'] = news['word_clean'].apply(lambda x: [i for i in x if i not in remove_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['word_final'] = news['word_clean'].apply(lambda x: [i for i in x if i not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news.drop(100, inplace = True)\n",
    "news = news.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 篩出正向文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_pos(x,list_name):\n",
    "    l = []\n",
    "    for i in x:\n",
    "        if i in pos_ys:\n",
    "            l.append(i)\n",
    "    list_name.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pos = []\n",
    "news['word_clean'].apply(lambda x:word_pos(x,list_pos))\n",
    "news['word_pos'] = list_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = ['有益', '創意', '安可']\n",
    "news.loc[news['name'].isin(['創意', '安可', '有益']),'word_pos'] = news.loc[news['name'].isin(['創意', '安可', '有益']),'word_pos'].apply(lambda x: [i for i in x if i not in remove_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 篩出負向文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_neg(x,list_name):\n",
    "    l = []\n",
    "    for i in x:\n",
    "        if i in neg_ys:\n",
    "            l.append(i)\n",
    "    list_name.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_neg = []\n",
    "news['word_clean'].apply(lambda x:word_neg(x,list_neg))\n",
    "news['word_neg'] = list_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 計算正負向字詞數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['raw_article'] = news['word_clean'].apply(lambda x:len(x))\n",
    "news['len_article'] = news['word_final'].apply(lambda x:len(x))\n",
    "news['raw_pos'] = news['word_pos'].apply(lambda x:len(x))\n",
    "news['raw_neg'] = news['word_neg'].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 調整否定詞的影響"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index of each postive words in news\n",
    "list_index = []\n",
    "for i in range(5667):\n",
    "    search_set = set(news['word_pos'][i])\n",
    "    l_ = []\n",
    "    for j in search_set:\n",
    "        l_.extend(np.where(np.array(news['word_clean'][i]) == j)[0])\n",
    "    list_index.append(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find previous and next 2 words of postive words\n",
    "word_token = []\n",
    "for i in range(5667):\n",
    "    token = []\n",
    "    for j in list_index[i]:\n",
    "        token.append(news['word_clean'][i][j-2:j+3])\n",
    "    word_token.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_word = ['不', '不易','沒有', '還沒', '還','不會', '擺脫', '免去', \n",
    "                 '避免', '非常', '無', '沒', '仍需', '解決', '走']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if negation word exist in the pre/next words of postive words\n",
    "word_count = []\n",
    "for i in word_token:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if len(list(set(negation_word).intersection(set(j)))) > 0:\n",
    "            count +=1\n",
    "    word_count.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['adjusted_pos'] = word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整後的正負向字詞個數\n",
    "news['len_pos'] = news['raw_pos'] - news['adjusted_pos']\n",
    "news['len_neg'] = news['raw_neg'] + news['adjusted_pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **計算情緒(sentiment)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 篩選公司\n",
    "IPO_CODE = pd.read_excel('./IPO_USECODE.xlsx')\n",
    "IPO_name_list = IPO_CODE['name'].unique().tolist()\n",
    "news = news[news['name'].isin(IPO_name_list)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 計算 Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正負向詞彙比重\n",
    "news['P'] = news['len_pos']/news['len_article']\n",
    "news['N'] = news['len_neg']/news['len_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算情緒\n",
    "news['sentiment'] = (news['len_pos'] - news['len_neg'])/news['len_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['len_sentiment'] =  news['len_pos'] - news['len_neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle\n",
    "news.to_pickle('news.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 計算平均 Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = news.groupby('name').agg({'len_pos':'mean', 'len_neg':'mean', 'len_sentiment':'mean',\n",
    "                                      'P':'mean', 'N':'mean','sentiment':'mean','name':'count'})\\\n",
    "                                .rename(columns = {'name':'n_article'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment.to_pickle('sentiment.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment.to_excel('sentiment.xlsx', index = False)\n",
    "# sentiment.to_excel('sentiment_ys_negation_1.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 計算上市前7天以前的 Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPO = pd.read_excel('IPO_RawData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df['underprice'] = df['close_price']/df['offer_price'] - 1 #IPO折價\n",
    "    df['stock_code'] = df['name'].str[:4] #擷取公司股票代碼\n",
    "    df['name'] = df['name'].str[5:] #擷取公司名稱\n",
    "clean(IPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 篩選IPO前七天日期\n",
    "IPO['ipo_date_minus'] = IPO['ipo_date'] - timedelta(days=7)\n",
    "IPO = IPO[IPO['name'].isin(news['name'].unique().tolist())].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 篩選新聞\n",
    "news_turnover = pd.DataFrame({'content':[], 'date':[], 'name':[], 'title':[], 'word_es':[], 'word_pos':[], 'word_seg':[],\n",
    "                              'word_clean':[], 'word_final':[], 'word_neg':[], 'raw_article':[], 'len_article':[],\n",
    "                              'raw_pos':[], 'raw_neg':[], 'adjusted_pos':[], 'len_pos':[], 'len_neg':[], 'P':[], 'N':[],\n",
    "                              'polarity':[], 'sentiment':[], 'len_sentiment':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(IPO['name'], IPO['ipo_date_minus']):\n",
    "    news_turnover = news_turnover.append(news[(news['name'] == i) & (news['date'] < j)])\n",
    "# news_turnover = news_turnover(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_turnover = news_turnover.groupby('name')\\\n",
    "                     .agg({'len_pos':'mean', 'len_neg':'mean', 'len_sentiment':'mean',\n",
    "                           'P':'mean', 'N':'mean','sentiment':'mean','name':'count'})\\\n",
    "                     .rename(columns = {'name':'n_article'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_turnover.columns = ['name','len_pos_turnover', 'len_neg_turnover', 'len_sentiment_turnover', 'P_turnover', 'N_turnover', \n",
    "                              'sentiment_turnover', 'polarity_turnover', 'n_article_turnover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = sentiment.merge(sentiment_turnover, on = 'name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.to_excel('sentiment.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.to_pickle('sentiment.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
